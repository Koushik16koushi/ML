import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import make_pipeline
import warnings
warnings.filterwarnings('ignore')

# ---------- LINEAR REGRESSION ON BOSTON HOUSING ----------
def linear_regression_boston_housing():
    # Load and clean Boston Housing data
    data = pd.read_csv('Downloads/Datasets/Boston housing dataset.csv')
    print(data.head())
    print(data.shape)
    print(data.info())
    print(data.isnull().sum())
    

    df = data.copy()
    # Fill missing values as per the PDF
    df['CRIM'].fillna(df['CRIM'].mean(), inplace=True)
    df['ZN'].fillna(df['ZN'].mean(), inplace=True)
    df['CHAS'].fillna(df['CHAS'].mode()[0], inplace=True)
    df['INDUS'].fillna(df['INDUS'].mean(), inplace=True)
    df['AGE'].fillna(df['AGE'].median(), inplace=True)
    df['LSTAT'].fillna(df['LSTAT'].median(), inplace=True)
    df['CHAS'] = df['CHAS'].astype(int)
    print(df.isnull().sum())
    print(df.describe().T)


    # Split into features and target
    X = df.drop('MEDV', axis=1)
    y = df['MEDV']

    # Standardize the features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

    # Train model
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    # Output
    print("----- Linear Regression: Boston Housing Dataset -----")
    print(f"Mean Squared Error: {mse}")
    print(f"Root Mean Squared Error: {rmse}")
    print(f"R-squared: {r2}")
    

    # ------- 2D PLOT USING 'RM' FEATURE ONLY -------
    X_rm = df[['RM']].values
    y_rm = df['MEDV'].values

    X_train_rm, X_test_rm, y_train_rm, y_test_rm = train_test_split(X_rm, y_rm, test_size=0.2, random_state=42)

    model_rm = LinearRegression()
    model_rm.fit(X_train_rm, y_train_rm)
    y_pred_rm = model_rm.predict(X_test_rm)

    plt.scatter(X_test_rm, y_test_rm, color='blue', label='Actual')
    plt.plot(X_test_rm, y_pred_rm, color='red', label='Predicted')
    plt.xlabel("Average Number of Rooms (RM)")
    plt.ylabel("Median House Value (MEDV)")
    plt.title("Linear Regression - RM vs MEDV (Boston Housing)")
    plt.legend()
    plt.show()




    

# ---------- Main ----------
if __name__ == "__main__":
    linear_regression_boston_housing()












# ---------- POLYNOMIAL REGRESSION ON AUTO MPG ----------
def polynomial_regression_auto_mpg():
    df = sns.load_dataset('mpg')
    df = df.copy()
    df['horsepower'].fillna(df['horsepower'].median(), inplace=True)

    X = df[['horsepower']].values
    y = df['mpg'].values

    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Polynomial regression pipeline
    poly_model = make_pipeline(PolynomialFeatures(degree=2), StandardScaler(), LinearRegression())
    poly_model.fit(X_train, y_train)
    y_pred = poly_model.predict(X_test)

    # Plot
    plt.scatter(X_test, y_test, color='blue', label='Actual')
    plt.scatter(X_test, y_pred, color='red', label='Predicted')
    plt.xlabel('Horsepower')
    plt.ylabel('Miles per Gallon (mpg)')
    plt.title('Polynomial Regression - Auto MPG Dataset')
    plt.legend()
    plt.show()

    # Metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print("----- Polynomial Regression: Auto MPG Dataset -----")
    print(f"Mean Squared Error: {mse}")
    print(f"Root Mean Squared Error: {rmse}")
    print(f"R-squared: {r2}")

    

# ---------- Main ----------
if __name__ == "__main__":
    polynomial_regression_auto_mpg()


